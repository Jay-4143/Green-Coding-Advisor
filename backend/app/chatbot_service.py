import logging
import ollama
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

class GreenCodingChatbot:
    """AI-powered chatbot using LLaMA-2 via Ollama"""
    
    SYSTEM_PROMPT = """
You are the **Green Coding Architect**, an advanced AI assistant powered by LLaMA-2, dedicated to sustainable software engineering.
Your goal is to guide developers in writing code that reduces energy consumption, carbon footprint, and computational overhead.

**Your Core Principles:**
1. **Efficiency First**: Always prioritize algorithms with lower Time and Space complexity (Big-O).
2. **Resource Awareness**: Highlight memory usage, CPU cycles, and network bandwidth.
3. **Sustainable Syntax**: Recommend language-specific features that are optimized (e.g., list comprehensions in Python, avoiding unnecessary copies).
4. **Hardware Empathy**: Explain how code decisions affect underlying hardware (battery life, heat generation).

**Response Guidelines:**
- Be concise but educational.
- **Always** provide a brief code example if applicable.
- Conclude with a "Green Impact" statement explaining *why* your advice saves energy.
- Use a professional, encouraging tone.

If the user asks about non-coding topics, politely redirect them to sustainable technology.
"""

    def __init__(self, model_name: str = "llama2"):
        self.model_name = model_name
        self._ensure_model_exists()

    def _ensure_model_exists(self):
        """Check if model exists, warn if not (async check might be better in production)"""
        try:
            # We assume the user has pulled the model. 
            # In a real app, we might check `ollama.list()` here.
            pass
        except Exception as e:
            logger.warning(f"Ollama connection issue: {e}")

    def answer(self, message: str, context: Optional[Dict] = None) -> Dict[str, any]:
        """Generate a response using LLaMA-2"""
        try:
            # Call Ollama API
            response = ollama.chat(model=self.model_name, messages=[
                {'role': 'system', 'content': self.SYSTEM_PROMPT},
                {'role': 'user', 'content': message},
            ])
            
            answer_text = response['message']['content']
            
            # Simple topic extraction based on response content
            topics = self._extract_topics(answer_text + " " + message)
            
            return {
                "answer": answer_text,
                "suggestions": self._generate_suggestions(answer_text),
                "related_topics": topics
            }
            
        except Exception as e:
            logger.error(f"Error calling Ollama: {e}")
            return {
                "answer": "I'm currently unable to connect to my local LLaMA-2 brain (Ollama). Please ensure Ollama is running (`ollama serve`) and you have pulled the model (`ollama pull llama2`).\n\nIn the meantime, here is a general tip: **Optimize loops and avoid unnecessary I/O to reduce energy consumption.**",
                "suggestions": ["How to optimize loops?", "What is green coding?"],
                "related_topics": ["connection_error"]
            }

    def _extract_topics(self, text: str) -> List[str]:
        """Extract green coding topics from text"""
        text_lower = text.lower()
        topics = set()
        if "loop" in text_lower: topics.add("loop_optimization")
        if "memory" in text_lower or "ram" in text_lower: topics.add("memory_usage")
        if "complexity" in text_lower or "big o" in text_lower: topics.add("algorithm_complexity")
        if "data structure" in text_lower: topics.add("data_structures")
        if "carbon" in text_lower or "emission" in text_lower: topics.add("carbon_tracking")
        return list(topics)

    def _generate_suggestions(self, context_text: str) -> List[str]:
        """Generate static follow-up suggestions based on context"""
        # Ideally this would also be generated by LLM, but static is faster for UI
        base_suggestions = [
            "How can I measure my code's energy?",
            "What are the most energy-efficient languages?",
            "Explain Python list comprehension efficiency."
        ]
        return base_suggestions

# Global chatbot instance
green_chatbot = GreenCodingChatbot()

